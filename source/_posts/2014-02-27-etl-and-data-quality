---
layout: post
title: "ETL - producing better quality data"
date: 2014-02-27 08:12:44 +0000
comments: true
published: false
categories: [Data cleaning, ETL]
author: Janos Matyas
---

On my way to work this morning I read an interesting article about the quality of data being produced by different systems and applications. While the article was emphasizing that the quality of the data should not be an IT problem (but management), our believe is that at the high volume, velocity and variety (the "3Vs" of big data) the data is produced today, the process of producing data is a shared responsibility between management and the IT department.

Since the emerging of Hadoop, the TCO of storing large amounts of data in HDFS is lower than ever before - and now it makes sense to store all the data an enterprise produces in order to find patterns, correlations and break the data silos - something which was very specific for different departments within an organization. Storing such an amount of data (structured, unstructured, logs, clickstream, etc) inevitable produces a 'bad' data quality - but this depends on your point of view. For us data is just data - we don't want to qualify it - and has it's own intrinsic value, but the quality of it depends on the ETL process. When someone engages with our API and the xTract Spacetime platform, among the first step is the configuration of data sources, and the attached ETL processes. We offer an extremely sophisticated ETL process and the ability to 'clean' the data (batch or streaming) while arrives into xTract Spacetime, but we always suggest our customers to keep the raw data as well.

During the architecture of the xTract Spacetime platform we have tried and PoCd different ETL frameworks and implementations - and we choose [Kite Morphlines](https://github.com/kite-sdk/kite/tree/master/kite-morphlines) being at the core of our ETL process. Among the first reasons we stick with Morphlines was the scalability - we have seen enterprises producing 50 terabytes data per day and missing the 24 hour ETL window. Morphlines is built on top of the Kite framework (a great framework for making easier to build systems on top of the Hadoop). 
We found it easy to embed into our data streaming part of the system but Morphlines can also be embedded with MR, Crunch, HBase, Hive, Pig and Sqoop as well. Since our goal from the very beginning was to create data lakes, instead of data silos the ability to load data into HDFS, HBase and Apache Solr was a very important feature as well.

We would like to give you a quick idea and code examples about how to use Morphline and ETL on large sets of streaming data, so keep on reading our blog - the second part will follow up shortly.
