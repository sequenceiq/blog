<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[SequenceIQ Blog]]></title>
  <link href="http://blog.sequenceiq.com//atom.xml" rel="self"/>
  <link href="http://blog.sequenceiq.com//"/>
  <updated>2014-02-26T12:38:54+00:00</updated>
  <id>http://blog.sequenceiq.com//</id>
  <author>
    <name><![CDATA[SequenceIQ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Vote for us - 2014 Hadoop Summit San Jose]]></title>
    <link href="http://blog.sequenceiq.com//blog/2014/02/26/vote-for-us/"/>
    <updated>2014-02-26T10:17:04+00:00</updated>
    <id>http://blog.sequenceiq.com//blog/2014/02/26/vote-for-us</id>
    <content type="html"><![CDATA[<p>While we are extremely proud that our abstract came 2nd (out of 107) in the 2014 Hadoop Summit in Amsterdam (see you all there in April 2-3), we will not stop there and our plan is to continue the hard work and we&rsquo;re looking forward to meet you at 2014 Hadoop Summit in San Jose.
We would like to ask for your support by submitting your vote for our session in the largest Hadoop conference in the world.</p>

<p>Please use the following link to vote, or read our abstract below.</p>

<p><a href="http://hadoopsummit.uservoice.com/forums/242807-hadoop-deployment-operations-track/suggestions/5568417-moving-to-hadoop-2-0-yarn-at-sequenceiq">Vote for us</a></p>

<p>Should you have any questions regarding our abstract, and the technical solution or implementation feel free to contact us or
check our <a href="https://github.com/sequenceiq">GitHub</a> page.</p>

<p><strong>Moving to Hadoop 2.0/YARN at SequenceIQ</strong></p>

<p>A showcase of our efforts to bring all our Hadoop based applications under one common cluster management framework &ndash; YARN.
Our deployment consists of MR2, HBase, Mahout and Hive-all running within one single auto-scaling cluster. We have faced many challenges such as load imbalances, SLA misses, cluster scheduling and VM container deployments &ndash; and would like to share our struggle and solution with the community.
As a startup, cost savings is important for us &ndash; switching to Hadoop 2.0 helped us save significant costs through better utilization of our hardware and cloud VMs. Our decision and investment of moving to YARN has paid off &ndash; and opened up new business and technical opportunities.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Custom Apache Flume source]]></title>
    <link href="http://blog.sequenceiq.com//blog/2014/02/22/custom-flume-source/"/>
    <updated>2014-02-22T14:45:48+00:00</updated>
    <id>http://blog.sequenceiq.com//blog/2014/02/22/custom-flume-source</id>
    <content type="html"><![CDATA[<p>The process of data analytics starts with collecting the data into a common system, in our case a Hadoop cluster. Flume is an Apache project aiming to help us solve this problem in a very efficient and elegant way.</p>

<p>In Flume terminology a source is responsible to listen and consume events coming from many distributed clients and forwards them to one or more channels. Events can have any arbitrary format, it all depends on what source do we use. Flume provides many sources, but only a few of them is capable to collect data through network.</p>

<p>In this article I will discuss how you can implement your own that meets your demands through creating a websocket source.
There are two types of sources: event driven and pollable. In case of a pollable source, Flume will start a thread to periodically call the following method to check whether there is new data available or not:</p>

<figure class='code'><figcaption><span>PollableSource interface</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="n">Status</span> <span class="nf">process</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">EventDeliveryException</span><span class="o">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>With event driven source you will have to take care yourself of receiving the data from the clients. For our websocket example we will use embedded Jetty 9.1. Extend the AbstractEventDrivenSource class and override the mandatory methods to bootstrap the source. In the doConfigure method you can ask the properties you need from the context. These properties are coming from your agent’s configuration file. More on this later..</p>

<figure class='code'><figcaption><span>protected void doConfigure(Context context)</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>    <span class="k">this</span><span class="o">.</span><span class="na">host</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="n">HOST_KEY</span><span class="o">);</span>
</span><span class='line'>    <span class="k">this</span><span class="o">.</span><span class="na">port</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">getInteger</span><span class="o">(</span><span class="n">PORT_KEY</span><span class="o">);</span>
</span><span class='line'>    <span class="k">this</span><span class="o">.</span><span class="na">path</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="n">PATH_KEY</span><span class="o">);</span>
</span><span class='line'>    <span class="k">this</span><span class="o">.</span><span class="na">enableSsl</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="na">getBoolean</span><span class="o">(</span><span class="n">SSL_KEY</span><span class="o">,</span> <span class="kc">false</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Eventually the doStart will kick off the embedded Jetty as shown:</p>

<figure class='code'><figcaption><span>protected void doStart()</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="k">try</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">JettyWebSocketServer</span> <span class="n">server</span> <span class="o">=</span> <span class="k">new</span> <span class="n">JettyWebSocketServer</span><span class="o">(</span><span class="n">host</span><span class="o">,</span> <span class="n">port</span><span class="o">,</span> <span class="n">path</span><span class="o">,</span> <span class="n">getChannelProcessor</span><span class="o">());</span>
</span><span class='line'>    <span class="n">server</span><span class="o">.</span><span class="na">start</span><span class="o">();</span>
</span><span class='line'><span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">LOGGER</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="s">&quot;Error starting jetty server&quot;</span><span class="o">,</span> <span class="n">e</span><span class="o">);</span>
</span><span class='line'>    <span class="k">throw</span> <span class="k">new</span> <span class="nf">FlumeException</span><span class="o">(</span><span class="n">e</span><span class="o">);</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<!-- more -->


<p>Channel processor plays an important role here. Its purpose to forward the incoming events to the configured channels.</p>

<p>Creating an embedded Jetty server is pretty easy and straightforward even with SSL support. I am not going into details you can find the source code here <a href="https://github.com/sequenceiq/sequenceiq-samples">https://github.com/sequenceiq/sequenceiq-samples</a> You will have to create a Servlet which will create a new listener for every session or you can just simply ignore some requests based on different headers. On new message all you have to do is create a flume event out of it and pass is to the channelprocessor.</p>

<figure class='code'><figcaption><span>public void onWebSocketText(String s) </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">SimpleEvent</span> <span class="n">event</span> <span class="o">=</span> <span class="k">new</span> <span class="n">SimpleEvent</span><span class="o">();</span>
</span><span class='line'><span class="n">event</span><span class="o">.</span><span class="na">setBody</span><span class="o">(</span><span class="n">s</span><span class="o">.</span><span class="na">getBytes</span><span class="o">());</span>
</span><span class='line'><span class="n">channelProcessor</span><span class="o">.</span><span class="na">processEvent</span><span class="o">(</span><span class="n">event</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>From this point the data will travel through the configured channels and sinks to end up on its final destination. It is committed in one transaction so if any component fails the whole process fails.</p>

<p>To deploy your custom source put the packaged jar to Flume’s classpath.</p>

<blockquote><p>Flume now supports a special directory called plugins.d which automatically picks up plugins that are packaged in a specific format.</p></blockquote>


<p>e.g plugins.d/websocket/lib/yoursource.jar</p>

<p>From now on you can use it:<br/>
agent.sources = websocket<br/>
agent.sources.websocket.type = com.sequenceiq.samples.flume.source.JettyWebSocketSource<br/>
agent.sources.websocket.host = localhost<br/>
agent.sources.websocket.port = 60000<br/>
agent.sources.websocket.path = /flume</p>

<p>Test it directly from your browser:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">var</span> <span class="nx">ws</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">WebSocket</span><span class="p">(</span><span class="s2">&quot;ws://127.0.0.1:60000/flume&quot;</span><span class="p">)</span>
</span><span class='line'><span class="nx">ws</span><span class="p">.</span><span class="nx">send</span><span class="p">(</span><span class="s2">&quot;Some message&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>That&rsquo;s it. Hope you enjoyed. We will be back soon with some ETL processing examples.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Set up HDP2 on Amazon EC2]]></title>
    <link href="http://blog.sequenceiq.com//blog/2014/02/07/hdp2-on-amazon/"/>
    <updated>2014-02-07T16:17:04+00:00</updated>
    <id>http://blog.sequenceiq.com//blog/2014/02/07/hdp2-on-amazon</id>
    <content type="html"><![CDATA[<p>During the last years we have seen many blog entries and articles about how to set up Hadoop on Amazon EC2. All these tutorials and articles had one thing in common &ndash; you had to go through a large number of manual (and painful) steps, read screenshots and redo the whole thing all over again, in case you needed a new cluster.</p>

<p>Since we use Amazon EC2 quite a lot, and Hadoop as well (Hortonworks distribution) we have gone through these steps many times &ndash; and have scripted the whole process from the first steps up to launching an N node Hadoop/HDP2 cluster in less then five minutes.</p>

<p>Moreover, the cluster is a &lsquo;production ready&rsquo; setup from infrastructural point of view &ndash; it is provisioned in a logically isolated section of the cloud (Virtual Private Cloud), with his own IP address range, creation of subnets, and configuration of route tables and network gateways.</p>

<p>Once the instances are provisoned, the HDP2 setup is done by Apache Ambari &ndash; for more advanced users we will provide the setup thorugh Ambari&rsquo;s RESTful API &ndash; watch this space or our GitHub page.</p>

<p>All the EC2 instances are tagged with the user name &ndash; thus you can create different clusters for different employees, all under the same AWS account (with IAM).</p>

<p>We believe that this is the right way to provision Hadoop in the cloud &ndash; during development and testing we had to provision Hadoop clusters of different sizes, and going through these steps manually would take lots of time.
This way we are able to provision clusters in the cloud in the matter of minutes &ndash; independently of the size.</p>

<p>The script is available at: <a href="https://github.com/sequenceiq/hadoop-cloud-scripts">https://github.com/sequenceiq/hadoop-cloud-scripts</a></p>

<p>Enjoy,
SequenceIQ</p>
]]></content>
  </entry>
  
</feed>
